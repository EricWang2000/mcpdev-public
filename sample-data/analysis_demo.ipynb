{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryptocurrency Sentiment Analysis Demo\n",
    "\n",
    "This notebook demonstrates the statistical correlation analysis between Twitter sentiment and Bitcoin price movements using sample data from June 15, 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Load sample datasets\n",
    "tweets = pd.read_csv('sample_tweets.csv', parse_dates=['timestamp'])\n",
    "prices = pd.read_csv('sample_prices.csv', parse_dates=['timestamp'])\n",
    "\n",
    "print(f\"Loaded {len(tweets)} tweets and {len(prices)} price records\")\n",
    "print(f\"\\nDate range: {tweets['timestamp'].min()} to {tweets['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample tweets\n",
    "print(\"Sample tweets with sentiment scores:\\n\")\n",
    "print(tweets[['timestamp', 'handle', 'avg_score']].head(10))\n",
    "\n",
    "# Sentiment statistics\n",
    "print(\"\\nSentiment Score Statistics:\")\n",
    "print(tweets['avg_score'].describe())\n",
    "print(f\"\\nPositive tweets (score > 0): {(tweets['avg_score'] > 0).sum()}\")\n",
    "print(f\"Negative tweets (score < 0): {(tweets['avg_score'] < 0).sum()}\")\n",
    "print(f\"Neutral tweets (score = 0): {(tweets['avg_score'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample prices\n",
    "print(\"Bitcoin hourly prices:\\n\")\n",
    "print(prices[['timestamp', 'price', 'volume_24h']].head(10))\n",
    "\n",
    "# Price statistics\n",
    "print(\"\\nPrice Statistics:\")\n",
    "print(prices['price'].describe())\n",
    "print(f\"\\nPrice range: ${prices['price'].min():.2f} - ${prices['price'].max():.2f}\")\n",
    "print(f\"Price volatility (std dev): ${prices['price'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregate Sentiment by Hour\n",
    "\n",
    "To correlate with hourly price data, we aggregate multiple tweets within each hour into a single sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round timestamps to nearest hour\n",
    "tweets['hour'] = tweets['timestamp'].dt.floor('H')\n",
    "prices['hour'] = prices['timestamp'].dt.floor('H')\n",
    "\n",
    "# Aggregate sentiment by hour (mean)\n",
    "hourly_sentiment = tweets.groupby('hour').agg({\n",
    "    'avg_score': 'mean',\n",
    "    'handle': 'count'\n",
    "}).rename(columns={'handle': 'tweet_count', 'avg_score': 'hourly_sentiment'})\n",
    "\n",
    "print(f\"Aggregated into {len(hourly_sentiment)} hourly sentiment values\")\n",
    "print(\"\\nHourly sentiment samples:\")\n",
    "print(hourly_sentiment.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge Sentiment and Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on hour\n",
    "merged = pd.merge(\n",
    "    hourly_sentiment,\n",
    "    prices[['hour', 'price', 'volume_24h']],\n",
    "    on='hour',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset: {len(merged)} records with both sentiment and price\")\n",
    "print(\"\\nMerged data sample:\")\n",
    "print(merged.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Pearson Correlation\n",
    "\n",
    "Implementation of Pearson correlation coefficient from first principles:\n",
    "\n",
    "$$r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\cdot \\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pearson_correlation(x, y):\n",
    "    \"\"\"\n",
    "    Calculate Pearson correlation coefficient manually.\n",
    "    \n",
    "    Args:\n",
    "        x, y: Arrays of equal length\n",
    "    \n",
    "    Returns:\n",
    "        float: Pearson correlation coefficient (-1 to +1)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate means\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate deviations and products\n",
    "    sum_xy = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))\n",
    "    sum_x2 = sum((x[i] - mean_x) ** 2 for i in range(n))\n",
    "    sum_y2 = sum((y[i] - mean_y) ** 2 for i in range(n))\n",
    "    \n",
    "    # Calculate correlation\n",
    "    denominator = (sum_x2 * sum_y2) ** 0.5\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    \n",
    "    correlation = sum_xy / denominator\n",
    "    return correlation\n",
    "\n",
    "# Extract arrays\n",
    "sentiment_array = merged['hourly_sentiment'].values\n",
    "price_array = merged['price'].values\n",
    "\n",
    "# Calculate correlation\n",
    "r = calculate_pearson_correlation(sentiment_array, price_array)\n",
    "r_squared = r ** 2\n",
    "\n",
    "print(f\"Pearson Correlation (r): {r:.4f}\")\n",
    "print(f\"Coefficient of Determination (R²): {r_squared:.4f}\")\n",
    "print(f\"\\nInterpretation: {abs(r_squared * 100):.2f}% of price variance is explained by sentiment\")\n",
    "\n",
    "# Verify with pandas\n",
    "pandas_r = merged['hourly_sentiment'].corr(merged['price'])\n",
    "print(f\"\\nVerification (pandas): {pandas_r:.4f}\")\n",
    "print(f\"Difference: {abs(r - pandas_r):.10f} (should be near zero)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistical Interpretation\n",
    "\n",
    "Classification of correlation strength based on |r| value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_correlation(r):\n",
    "    \"\"\"Classify correlation strength.\"\"\"\n",
    "    abs_r = abs(r)\n",
    "    \n",
    "    if abs_r < 0.3:\n",
    "        return \"Very weak\"\n",
    "    elif abs_r < 0.5:\n",
    "        return \"Weak\"\n",
    "    elif abs_r < 0.7:\n",
    "        return \"Moderate\"\n",
    "    elif abs_r < 0.9:\n",
    "        return \"Strong\"\n",
    "    else:\n",
    "        return \"Very strong\"\n",
    "\n",
    "classification = interpret_correlation(r)\n",
    "direction = \"positive\" if r > 0 else \"negative\"\n",
    "\n",
    "print(f\"Correlation Classification: {classification} {direction}\")\n",
    "print(f\"\\nConclusion:\")\n",
    "print(f\"This {classification.lower()} correlation suggests that Twitter sentiment\")\n",
    "print(f\"has minimal predictive power for Bitcoin price movements in this sample.\")\n",
    "print(f\"Only {r_squared * 100:.1f}% of price variance can be explained by sentiment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Directional Movement Analysis\n",
    "\n",
    "Calculate what percentage of the time sentiment and price move in the same direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate changes (deltas)\n",
    "merged_sorted = merged.sort_values('hour').reset_index(drop=True)\n",
    "merged_sorted['sentiment_change'] = merged_sorted['hourly_sentiment'].diff()\n",
    "merged_sorted['price_change'] = merged_sorted['price'].diff()\n",
    "\n",
    "# Remove first row (NaN from diff)\n",
    "changes = merged_sorted.dropna()\n",
    "\n",
    "# Check if changes have same sign\n",
    "same_direction = (\n",
    "    (changes['sentiment_change'] > 0) & (changes['price_change'] > 0)\n",
    ") | (\n",
    "    (changes['sentiment_change'] < 0) & (changes['price_change'] < 0)\n",
    ")\n",
    "\n",
    "same_direction_pct = (same_direction.sum() / len(changes)) * 100\n",
    "\n",
    "print(f\"Directional Analysis:\")\n",
    "print(f\"Same direction: {same_direction.sum()} / {len(changes)} ({same_direction_pct:.1f}%)\")\n",
    "print(f\"Opposite direction: {(~same_direction).sum()} / {len(changes)} ({100 - same_direction_pct:.1f}%)\")\n",
    "print(f\"\\nRandom chance would be 50%. Observed: {same_direction_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Event Detection\n",
    "\n",
    "Identify sentiment spikes and measure subsequent price impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sentiment spike threshold (1 standard deviation)\n",
    "sentiment_mean = merged['hourly_sentiment'].mean()\n",
    "sentiment_std = merged['hourly_sentiment'].std()\n",
    "threshold = sentiment_std\n",
    "\n",
    "print(f\"Sentiment Statistics:\")\n",
    "print(f\"Mean: {sentiment_mean:.4f}\")\n",
    "print(f\"Std Dev: {sentiment_std:.4f}\")\n",
    "print(f\"Threshold for spikes: ±{threshold:.4f}\")\n",
    "\n",
    "# Detect positive and negative sentiment events\n",
    "merged_sorted['is_positive_spike'] = merged_sorted['hourly_sentiment'] > (sentiment_mean + threshold)\n",
    "merged_sorted['is_negative_spike'] = merged_sorted['hourly_sentiment'] < (sentiment_mean - threshold)\n",
    "\n",
    "positive_spikes = merged_sorted[merged_sorted['is_positive_spike']]\n",
    "negative_spikes = merged_sorted[merged_sorted['is_negative_spike']]\n",
    "\n",
    "print(f\"\\nDetected Events:\")\n",
    "print(f\"Positive sentiment spikes: {len(positive_spikes)}\")\n",
    "print(f\"Negative sentiment spikes: {len(negative_spikes)}\")\n",
    "\n",
    "if len(positive_spikes) > 0:\n",
    "    print(f\"\\nPositive spike examples:\")\n",
    "    print(positive_spikes[['hour', 'hourly_sentiment', 'price']])\n",
    "\n",
    "if len(negative_spikes) > 0:\n",
    "    print(f\"\\nNegative spike examples:\")\n",
    "    print(negative_spikes[['hour', 'hourly_sentiment', 'price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "Key findings from this sample analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  - Tweets analyzed: {len(tweets)}\")\n",
    "print(f\"  - Price records: {len(prices)}\")\n",
    "print(f\"  - Merged hourly records: {len(merged)}\")\n",
    "print(f\"  - Date: June 15, 2025\")\n",
    "\n",
    "print(f\"\\nStatistical Results:\")\n",
    "print(f\"  - Pearson correlation (r): {r:.4f}\")\n",
    "print(f\"  - R² (variance explained): {r_squared:.4f} ({r_squared * 100:.2f}%)\")\n",
    "print(f\"  - Classification: {classification} {direction}\")\n",
    "print(f\"  - Same direction movements: {same_direction_pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nConclusion:\")\n",
    "print(f\"  Twitter sentiment shows a {classification.lower()} correlation with Bitcoin price.\")\n",
    "print(f\"  Sentiment explains only {r_squared * 100:.1f}% of price variance, suggesting\")\n",
    "print(f\"  limited predictive power for short-term price movements.\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\\nNote: This is a sample analysis with limited data (1 day).\")\n",
    "print(\"Full research used 4,441 hourly records showing similar weak correlations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
